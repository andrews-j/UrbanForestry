{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e8f509-aebf-4139-861c-702e581804a6",
   "metadata": {},
   "source": [
    "At the end of DataPrep we download two .csv files: \"F23_DataPrep.csv\" and \"S23_DataPrep.csv\"\n",
    "Before brining them back into Python in this notebook, I did some manual work in Excel, deleting and moving columns so they align."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b22ca3-2afa-4fed-936c-bbdc049177db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1a541-9714-4767-bb7f-81eeb4990e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "F23 = gpd.read_file(\"Merge_Ready/F23_modified.csv\")\n",
    "S23 = gpd.read_file(\"Merge_Ready/S23_modified.csv\")\n",
    "baseline = gpd.read_file(\"Input_Data/DCRreplanted141516gisfieldmap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eefc69-6885-4f0e-bc0a-0661aeddfe13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the columns match\n",
    "if set(S23.columns) == set(F23.columns):\n",
    "    # Columns match, so you can combine the dataframes\n",
    "    combined = pd.concat([S23, F23], ignore_index=True)\n",
    "else:\n",
    "    print(\"Columns do not match. Cannot combine dataframes.\")\n",
    "    \n",
    "# Set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Check the first few rows of the combined DataFrame\n",
    "#print(combined.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7c9aa-62db-400d-8089-93483ceb489e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standardize ObservationDate formatting\n",
    "# I wish I didn't have to do this in such an arcane way, but nothing else was working\n",
    "print(combined['EditDate'].unique())\n",
    "\n",
    "\n",
    "# Convert 'EditDate' column to datetime format\n",
    "for idx, date_str in enumerate(combined['EditDate']):\n",
    "    try:\n",
    "        # Try to convert the date string to datetime format\n",
    "        date_obj = pd.to_datetime(date_str)\n",
    "        if date_obj.strftime('%H:%M:%S') == '00:00:00':\n",
    "            # If time part is '00:00:00', convert to '%m/%d/%Y' format\n",
    "            combined.loc[idx, 'EditDate'] = date_obj.strftime('%m/%d/%Y')\n",
    "        else:\n",
    "            # Otherwise, convert to '%m/%d/%y' format\n",
    "            combined.loc[idx, 'EditDate'] = date_obj.strftime('%m/%d/%y')\n",
    "    except ValueError:\n",
    "        # If conversion fails, handle the exception here\n",
    "        # You can add custom logic to handle different date formats\n",
    "        pass\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba7a4e-673a-4013-bd9f-f099d734e22c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename the 'EditDate' column to 'ObservationDate_2023'\n",
    "combined = combined.rename(columns={'EditDate': 'ObservationDate_2023'})\n",
    "\n",
    "# And double check it all worked\n",
    "dates = sorted((combined['ObservationDate_2023'].unique()).tolist())\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbc99cc-cabb-44e6-8781-778a39fd1121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do the same for \"ObservationDate_baseline\"\n",
    "print(combined['ObservationDate_baseline'].unique())\n",
    "\n",
    "# Convert 'EditDate' column to datetime format\n",
    "for idx, date_str in enumerate(combined['ObservationDate_baseline']):\n",
    "    try:\n",
    "        # Try to convert the date string to datetime format\n",
    "        date_obj = pd.to_datetime(date_str)\n",
    "        if date_obj.strftime('%H:%M:%S') == '00:00:00':\n",
    "            # If time part is '00:00:00', convert to '%m/%d/%Y' format\n",
    "            combined.loc[idx, 'ObservationDate_baseline'] = date_obj.strftime('%m/%d/%Y')\n",
    "        else:\n",
    "            # Otherwise, convert to '%m/%d/%y' format\n",
    "            combined.loc[idx, 'ObservationDate_baseline'] = date_obj.strftime('%m/%d/%y')\n",
    "    except ValueError:\n",
    "        # If conversion fails, handle the exception here\n",
    "        # You can add custom logic to handle different date formats\n",
    "        pass\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58e883-0c61-4282-b280-5e9168be99d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# And double check it all worked\n",
    "baseline_dates = sorted((combined['ObservationDate_baseline'].unique()).tolist())\n",
    "baseline_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca23ec6-2ddc-45ec-bc10-406c34030509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check out species list\n",
    "print(len(S23['SPECIES'].unique()))\n",
    "print(len(F23['SPECIES'].unique()))\n",
    "print(len(combined['SPECIES'].unique()))\n",
    "species = sorted(combined['SPECIES'].unique().tolist())\n",
    "species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61edc6e2-9365-41ab-863f-3f6416d037e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# There are some errors and incomplete entries. \n",
    "# Lets correct common names where applicable\n",
    "combined['SPECIES'] = combined['SPECIES'].replace({'White Fur': 'White Fir'})\n",
    "combined['SPECIES'] = combined['SPECIES'].replace({'Japanese tree lilac': 'Japanese Tree Lilac'})\n",
    "combined['SPECIES'] = combined['SPECIES'].replace({'Linden': 'American Linden'})\n",
    "combined['SPECIES'] = combined['SPECIES'].replace({'Magnolia': 'Sweet Bay Magnolia'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd07f10-21e7-4366-89d2-3ee829091e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate SPECIES to Scientific.Name key dictionary \n",
    "species_to_scientific = {}\n",
    "\n",
    "# Iterate over unique species names\n",
    "for species in sorted(combined['SPECIES'].unique()):\n",
    "    # Get the corresponding scientific name for the species\n",
    "    scientific_name = combined.loc[combined['SPECIES'] == species, 'Scientific.Name'].iloc[0]\n",
    "    # Add the mapping to the dictionary\n",
    "    species_to_scientific[species] = scientific_name\n",
    "\n",
    "# Print the derived dictionary sorted by common name\n",
    "for species, scientific_name in species_to_scientific.items():\n",
    "    print(f\"{species}: {scientific_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8904b02-edf5-4938-bde7-7afc42b38801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Work a little GPT magic to generate the following\n",
    "# F23 did not have scientific names\n",
    "# Use key dictionary printed above, modify to correct errors and incomplete entries\n",
    "\n",
    "# Dictionary mapping species names to scientific names, sorted alphabetically by common name\n",
    "species_to_scientific = {\n",
    "    'American Arborvitae': 'Thuja occidentalis',\n",
    "    'American Linden': 'Tilia americana',\n",
    "    'Austrian Pine': 'Pinus nigra',\n",
    "    'Bald Cypress': 'Taxodium distichum',\n",
    "    'Balsam Fir': 'Abies balsamea',\n",
    "    'Beech': 'Fagus sylvatica',\n",
    "    'Blackgum': 'Nyssa sylvatica',\n",
    "    'Bradford Pear': 'Pyrus calleryana',\n",
    "    'Carolina Silverbell': 'Halesia carolina',\n",
    "    'Cherry': 'Prunus spp.',\n",
    "    'Colorado Spruce': 'Picea pungens',\n",
    "    'Crabapple': 'Malus sylvestris',\n",
    "    'Cucumber Magnolia': 'Magnolia acuminata',\n",
    "    'Dawn Redwood': 'Metasequoia glyptostroboides',\n",
    "    'Dogwood': 'Cornus florida',\n",
    "    'Fraser Fir': 'Abies fraseri',\n",
    "    'Fringetree': 'Chionanthus virginicus',\n",
    "    'Ginkgo': 'Ginkgo biloba',\n",
    "    'Golden Raintree': 'Koelreuteria paniculata',\n",
    "    'Hawthorn': 'Crataegus spp.',\n",
    "    'Honeylocust': 'Gleditsia triacanthos',\n",
    "    'Hophornbeam': 'Ostrya virginiana',\n",
    "    'Hornbeam': 'Carpinus betulus',\n",
    "    'Japanese Pagoda': 'Styphnolobium japonicum',\n",
    "    'Japanese Snowbell': 'Styrax japonicus',\n",
    "    'Japanese Stewartia': 'Stewartia pseudocamellia',\n",
    "    'Japanese Tree Lilac': 'Syringa reticulata',\n",
    "    'Juniper': 'Juniperus virginiana',\n",
    "    'Kousa Dogwood': 'Cornus kousa',\n",
    "    'Larch': 'Larix laricina',\n",
    "    'Littleleaf Linden': 'Tilia cordata',\n",
    "    'Sweet Bay Magnolia': 'Magnolia virginiana',\n",
    "    'Norway Spruce': 'Picea abies',\n",
    "    'Pin Oak': 'Quercus palustris',\n",
    "    'Red Oak': 'Quercus rubra',\n",
    "    'Sargent Cherry': 'Prunus sargentii',\n",
    "    'Scarlet Oak': 'Quercus coccinea',\n",
    "    'Serbian Spruce': 'Picea omorika',\n",
    "    'Serviceberry': 'Amelanchier spp.',\n",
    "    'Snow Goose Cherry': 'prunus serrulata',\n",
    "    'Sourwood': 'Oxydendrum arboreum',\n",
    "    'Swamp White Oak': 'Quercus bicolor',\n",
    "    'Sweetgum': 'Liquidambar styraciflua',\n",
    "    'Tulip': 'Liriodendron tulipifera',\n",
    "    'White Fir': 'Abies concolor',\n",
    "    'White Oak': 'Quercus alba',\n",
    "    'White Pine': 'Pinus strobus',\n",
    "    'Yellowwood': 'Cladrastis kentukea',\n",
    "    'Zelkova': 'Zelkova serrata'\n",
    "}\n",
    "\n",
    "# Fill in the 'Scientific.Name' column based on the mapping\n",
    "combined['Scientific.Name'] = combined['SPECIES'].map(species_to_scientific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5cb145-b693-475e-92da-ec3e95a6c415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run key dictionary generator again to double check it all looks good\n",
    "species_to_scientific = {}\n",
    "\n",
    "# Iterate over unique species names\n",
    "for species in sorted(combined['SPECIES'].unique()):\n",
    "    # Get the corresponding scientific name for the species\n",
    "    scientific_name = combined.loc[combined['SPECIES'] == species, 'Scientific.Name'].iloc[0]\n",
    "    # Add the mapping to the dictionary\n",
    "    species_to_scientific[species] = scientific_name\n",
    "\n",
    "# Print the derived dictionary sorted by common name\n",
    "for species, scientific_name in species_to_scientific.items():\n",
    "    print(f\"{species}: {scientific_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360726b-84f6-4d4a-8cb5-bd9b64e4caad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baselineColumns = baseline.columns.tolist()\n",
    "baselineColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ba40c-3aa9-4d1d-bc94-92ade1daec23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add forester column from baseline\n",
    "combined = pd.merge(combined, baseline[['ID','FORESTER']], on='ID', how='left')\n",
    "print(combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180774f-86ed-44e4-81c0-2e926e6bffab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = combined.columns.tolist()\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3becc5-17cd-48e9-b20e-6857d33ebf59",
   "metadata": {},
   "source": [
    "At this point I ran a script to get the unique values of every column in the dataframe excluding comments, notes, and address information\n",
    "The output is long, so I left it at the bottom of the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75851f87-fbc2-42b5-aad6-d4cae349c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Iterate over each column in the DataFrame\n",
    "for column in combined.columns:\n",
    "    # Check if the column contains either \"_baseline\" or \"_2023\" in the name\n",
    "    # and does not contain \"Comments\"\n",
    "    if (\"_baseline\" in column or \"_2023\" in column) and \"Comments\" not in column:\n",
    "        # Print the name of the column\n",
    "        print(f\"Unique values in column '{column}':\")\n",
    "        # Print the unique values of the column\n",
    "        print(combined[column].unique())\n",
    "        print()  # Add a newline for readability\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1a6b83-7b27-4c97-a530-2a0f7921ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'LandUse_baseline' and 'SiteType_baseline' are messy. We could replace with values from 2023. But it doesn't really matter. \n",
    "# I did not run this. \n",
    "\n",
    "# Replace values in 'LandUse_baseline' and 'SiteType_baseline' with values from 2023\n",
    "# combined['LandUse_baseline'] = combined['LandUse_2023']\n",
    "# combined['SiteType_baseline'] = combined['SiteType_2023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d6c22-5217-48b1-9665-fdb0a5f98674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unique values in column 'Mortality_baseline':\n",
    "# ['NA' 'Alive' 'Removed/Missing' '' 'Standing Dead' 'Removed/missing'\n",
    "# 'Unknown' 'Removed' 'Remove/Missing' 'N/A' 'Removed / missing' 'Unkown'\n",
    "# 'Stump' 'Removed/Missng' 'Removed ']\n",
    "\n",
    "# Define the mapping dictionary\n",
    "mapping = {\n",
    "    'NA': 'NA',\n",
    "    'Alive': 'Alive',\n",
    "    'Removed/Missing': 'Removed',\n",
    "    '': 'NA',\n",
    "    'Standing Dead': 'Standing Dead',\n",
    "    'Removed/missing': 'Removed',\n",
    "    'Unknown': 'Unknown',\n",
    "    'Remove/Missing': 'Removed',\n",
    "    'N/A': 'NA',\n",
    "    'Removed / missing': 'Removed',\n",
    "    'Unkown': 'Unknown',\n",
    "    'Stump': 'Stump',\n",
    "    'Removed/Missng': 'Removed',\n",
    "    'Removed ': 'Removed'\n",
    "}\n",
    "\n",
    "# Map the values using the mapping dictionary\n",
    "combined['Mortality_baseline'] = combined['Mortality_baseline'].map(mapping)\n",
    "\n",
    "# Fill NaN values with 'NA'\n",
    "combined['Mortality_baseline'].fillna('NA', inplace=True)\n",
    "\n",
    "# Print the unique values again to verify\n",
    "print(\"Unique values in column 'Mortality_baseline':\")\n",
    "print(combined['Mortality_baseline'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885319c-1bb5-4a70-aba6-849ea51e52f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean up Vigor_baseline\n",
    "\n",
    "# Define mapping for replacement\n",
    "replacement_mapping = {\n",
    "    '0': '',\n",
    "    ' ': '',\n",
    "    '1-25 %': '1',\n",
    "    '26-50 %': '2'\n",
    "}\n",
    "\n",
    "# Replace values in the column\n",
    "combined['Vigor_baseline'] = combined['Vigor_baseline'].replace(replacement_mapping)\n",
    "\n",
    "# Print unique values to verify\n",
    "print(\"Unique values in column 'Vigor_baseline':\")\n",
    "print(combined['Vigor_baseline'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1646204-62b1-4dd5-a9c6-85aa7e43d420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unique values in column 'Condition_baseline':\n",
    "# ['NA' 'Good' '0' '' 'Fair' 'Poor' 'Removed/Missing' 'Critical' ' ' '18']\n",
    "\n",
    "# Define replacement mapping\n",
    "replacement_mapping = {\n",
    "    '0': '',\n",
    "    ' ': '',\n",
    "    '18': 'Good',\n",
    "    'Removed/Missing': '',\n",
    "    'Critical': 'Poor'\n",
    "}\n",
    "\n",
    "# Replace values in the column\n",
    "combined['Condition_baseline'] = combined['Condition_baseline'].replace(replacement_mapping)\n",
    "\n",
    "# Print unique values to verify\n",
    "print(\"Unique values in column 'Condition_baseline':\")\n",
    "print(combined['Condition_baseline'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b23da7-dd69-463f-b86c-6ef1f07e3969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined = combined.rename(columns={'NOTES_baseline': 'LocationNotes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c503b7d6-8fed-492f-beec-b14899572fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unique values in column 'BasalSprouts_baseline':\n",
    "# ['NA' 'N' '' 'No' 'Y' 'Yes' 'Y(lots!)']\n",
    "\n",
    "# Define replacement mapping\n",
    "replacement_mapping = {\n",
    "    '0': 'N',\n",
    "    '1': 'Y'\n",
    "}\n",
    "\n",
    "# Replace values in the column\n",
    "combined['BasalSprouts_2023'] = combined['BasalSprouts_2023'].replace(replacement_mapping)\n",
    "\n",
    "# Print unique values to verify\n",
    "print(\"Unique values in column 'BasalSprouts_2023':\")\n",
    "print(combined['BasalSprouts_2023'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f2a06b-784c-4af2-8f91-7dd426c110f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unique values in column 'Vigor_2023':\n",
    "# ['1' '2' '0' '4' '3' '5' 'NA']\n",
    "\n",
    "# Define replacement mapping\n",
    "replacement_mapping = {\n",
    "    '0': '',\n",
    "    '5': ''\n",
    "}\n",
    "\n",
    "# Replace values in the column\n",
    "combined['Vigor_2023'] = combined['Vigor_2023'].replace(replacement_mapping)\n",
    "\n",
    "# Print unique values to verify\n",
    "print(\"Unique values in column 'Vigor_2023':\")\n",
    "print(combined['Vigor_2023'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c50d7b-5ed7-46ec-8f4b-615edd3d4410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unique values in column 'Condition_2023':\n",
    "# ['Good' 'Poor' '' 'Fair' 'Dead' 'NA']\n",
    "\n",
    "# Define replacement mapping\n",
    "replacement_mapping = {\n",
    "    'Dead': ''\n",
    "}\n",
    "\n",
    "# Replace values in the column\n",
    "combined['Condition_2023'] = combined['Condition_2023'].replace(replacement_mapping)\n",
    "\n",
    "# Print unique values to verify\n",
    "print(\"Unique values in column 'Condition_2023':\")\n",
    "print(combined['Condition_2023'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3ddbbd-428d-46b3-8461-6543a2abc627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Unique values in column 'BasalSprouts_baseline':\n",
    "#['NA' 'N' '' 'No' 'Y' 'Yes' 'Y(lots!)']\n",
    "\n",
    "# Define replacement mapping\n",
    "replacement_mapping = {\n",
    "    'No': 'N',\n",
    "    'Yes': 'Y',\n",
    "    'Y(lots!)': 'Y'\n",
    "}\n",
    "\n",
    "# Replace values in the column\n",
    "combined['BasalSprouts_baseline'] = combined['BasalSprouts_baseline'].replace(replacement_mapping)\n",
    "\n",
    "# Replace other empty strings with 'NA'\n",
    "combined['BasalSprouts_baseline'].replace('', 'NA', inplace=True)\n",
    "\n",
    "# Print unique values to verify\n",
    "print(\"Unique values in column 'BasalSprouts_baseline':\")\n",
    "print(combined['BasalSprouts_baseline'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c68c85-6f02-4b11-99aa-e617d9803b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save DataFrame F23 as a CSV file\n",
    "combined.to_csv('HERO2023_Final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52b9ad7-66fc-4926-bbae-f91dcf0dc617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this again at the end to double check \n",
    "# Iterate over each column in the DataFrame\n",
    "for column in combined.columns:\n",
    "    # Check if the column contains either \"_baseline\" or \"_2023\" in the name\n",
    "    # and does not contain \"Comments\"\n",
    "    if (\"_baseline\" in column or \"_2023\" in column) and \"Comments\" not in column:\n",
    "        # Print the name of the column\n",
    "        print(f\"Unique values in column '{column}':\")\n",
    "        # Print the unique values of the column\n",
    "        print(combined[column].unique())\n",
    "        print()  # Add a newline for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d22b1f-c982-46f0-9e8b-9d7bc8950795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38fff0-8b7e-4f2a-aace-aa1e184a2c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
