


import numpy as np
import geopandas as gpd
import pandas as pd


# This was done prior to current iteration of .csv files
"""
# Assuming S23_work is your DataFrame
# Convert the date columns to datetime format
S23_work['Observatio'] = pd.to_datetime(S23_work['Observatio'], errors='coerce')
S23_work['Observdate'] = pd.to_datetime(S23_work['Observdate'], errors='coerce')
S23_work['Observat_1'] = pd.to_datetime(S23_work['Observat_1'], errors='coerce')

# Create a new column "Observation_Date" with the most recent date
S23_work['Observation_Date'] = S23_work[['Observatio', 'Observdate', 'Observat_1']].max(axis=1)

# Drop the original date columns if needed
S23_work.drop(['Observatio', 'Observdate', 'Observat_1'], axis=1, inplace=True)

# Print the updated DataFrame
print(S23_work)
"""


F23 = gpd.read_file("Input_Data/Dataset_for_final_analysis_fall23.csv")
baseline = gpd.read_file("Input_Data/DCRreplanted141516gisfieldmap.csv")
S23 = gpd.read_file("Input_Data/S23_work.csv")


# Set display options to show all columns
pd.set_option('display.max_columns', None)

print(S23.head())


# Preliminary data cleaning
# Replace entries containing "1899" with "NA" in 'Observation_Date_baseline' column
S23.loc[S23['Observation_Date_baseline'].astype(str).str.contains("1899"), 'Observation_Date_baseline'] = "NA"
# Replace 'Unknown' with NA in 'SiteType_baseline' and 'LandUse_baseline' columns
S23.loc[S23['SiteType_baseline'].astype(str).str.contains("Unknown"), 'SiteType_baseline'] = "NA"
S23.loc[S23['LandUse_baseline'].astype(str).str.contains("Unknown"), 'LandUse_baseline'] = "NA"

# Replace values in 'Vigor_baseline' column
S23['Vigor_baseline'].replace({
    '1-25%': '1',
    '26-50%': '2',
    '51-75%': '3',
    '76-100%': '4'
}, inplace=True)

# Concatenate values from 'Comments_1', 'Comments_2', and 'Comments_3' into 'Comments_baseline'
S23['Comments_baseline'] = S23['Comments_1'].fillna('') + ' ' + S23['Comments_2'].fillna('') + ' ' + S23['Comments_3'].fillna('')

# Drop the original 'Comments_1', 'Comments_2', and 'Comments_3' columns if needed
S23.drop(['Comments_1', 'Comments_2', 'Comments_3'], axis=1, inplace=True)

# Capitalize all letters and remove commas in 'Crew_Initials' column
S23['Crew_Initials'] = S23['Crew_Initials'].str.upper().str.replace(',', '')


# Perform a left join on 'ID' column to add 'LONGITUDE' and 'LATITUDE' from baseline to S23
S23 = pd.merge(S23, baseline[['ID', 'LONGITUDE', 'LATITUDE']], on='ID', how='left')


# Check the number of rows in S23
# Should still be 2381
S23_rows = len(S23)
print("Number of rows:", S23_rows)

# Double check everything looks right
print(S23.head())


# view columns in baseline and F23 to see how coordinate data is organized
print(baseline.head())


print(F23.head())


# LAT and LON are Mass State Plane coordinates. 
# POINT_X and POINT_Y are EPSG 4326

# F23 already has the EPSG coordinates, but we should rename the columns to match as well while we are at it
F23 = F23.rename(columns={'x': 'POINT_X'})
F23 = F23.rename(columns={'y': 'POINT_Y'})


# Bring ESPSG coordinates to S23 as well
S23 = pd.merge(S23, baseline[['ID', 'POINT_X', 'POINT_Y']], on='ID', how='left')


print(S23.head())


# Now it's time to download these as .csv files and finalize column coordination
# Save DataFrame S23 as a CSV file
S23.to_csv('S23_DataPrep.csv', index=False)

# Save DataFrame F23 as a CSV file
F23.to_csv('F23_DataPrep.csv', index=False)



